# -*- coding: utf-8 -*-
"""1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zuObEGRlnb3409_yVscyWwWeUQrApzCm
"""

import keras
from keras.models import Sequential
from keras.layers import Dense,Flatten

(x_train,y_train),(x_text,y_text)=keras.datasets.mnist.load_data()

x_train.shape

y_train.shape

import numpy as np

num_class=len(np.unique(y_train))

num_class

x_train=x_train/255
x_text=x_text/255

model = Sequential()
model.add(Flatten(input_shape=(28,28)))
model.add(Dense(128,activation='relu'))
model.add(Dense(32,activation='relu'))
model.add(Dense(10,activation='softmax'))

model.summary()

model.compile(loss='sparse_categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])

history=model.fit(x_train,y_train,epochs=10,validation_data=(x_text,y_text))

y_prop=model.predict(x_text)

y_pred=y_prop.argmax(axis=1)

class_labels = ['class_0', 'class_1', 'class_2', 'class_3','class_4', 'class_5', 'class_6', 'class_7','class_8','class_9']

y_pred_classes = [class_labels[i] for i in y_pred]

from sklearn.metrics import accuracy_score
accuracy_score (y_text, y_pred)

import matplotlib.pyplot as plt
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend

plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.legend()

